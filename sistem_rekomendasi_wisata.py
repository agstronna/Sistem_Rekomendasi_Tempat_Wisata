# -*- coding: utf-8 -*-
"""Sistem_Rekomendasi_Wisata.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Xrwk3ZFLvrhwziHGUsJRMZY9TqQTnUh5

# **Sistem Rekomendasi Tempat Wisata di Bandung**

Nama: Agistia Ronna Aniqa

Cohort ID: MC299D5X1601

Menghubungkan Google Drive ke Colab.
"""

# Menghubungkan Google Drive ke Colab untuk akses file
from google.colab import drive
drive.mount('/content/drive')

"""Berpindah ke Direktori Proyek pada Google Drive."""

# Commented out IPython magic to ensure Python compatibility.
# Memindahkan direktori kerja ke folder proyek di Google Drive
# %cd /content/drive/MyDrive/Sistem_Rekomendasi_CodingCamp

"""## **Instal dan Import Library**

Menginstal library **Sastrawi** yang digunakan untuk preprocessing teks bahasa Indonesia, termasuk stopword removal dan stemming.
"""

# Instalasi library Sastrawi yang digunakan untuk proses stemming dan stopword removal pada teks berbahasa Indonesia
!pip install Sastrawi

"""Mengimpor library untuk analisis data, visualisasi, pemrosesan teks, manipulasi file, dan pembangunan model machine learning.

"""

# Library untuk analisis dan manipulasi data
import pandas as pd
import numpy as np

# Library untuk visualisasi data
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

# Library untuk pemrosesan teks
from sklearn.feature_extraction.text import TfidfVectorizer
from Sastrawi.Stemmer.StemmerFactory import StemmerFactory
from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory
from sklearn.metrics.pairwise import cosine_similarity

# Library untuk manipulasi file dan path
from zipfile import ZipFile
from pathlib import Path

# Library untuk pembangunan model deep learning
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

"""TF-IDF berfungsi mengonversi teks kategori wisata menjadi fitur numerik, sementara stemmer dan stopword remover digunakan untuk melakukan preprocessing teks seperti stemming dan penghapusan kata tidak penting.

"""

# TF-IDF Vectorizer dengan batas maksimal 5000 fitur untuk mengubah teks menjadi representasi numerik
tfidf_vectorizer_model = TfidfVectorizer(max_features=5000)

# Stemmer bahasa Indonesia untuk melakukan proses stemming
stem = StemmerFactory().create_stemmer()

# Stopword remover untuk menghapus kata-kata umum yang tidak memiliki makna penting dalam analisis
stopword = StopWordRemoverFactory().create_stop_word_remover()

"""Ketiga DataFrame ini menjadi sumber data utama untuk analisis dan pembuatan model rekomendasi.

- `df_rating` memuat data rating atau penilaian dari pengguna terhadap tempat wisata.  
- `df_place` memuat data informasi tempat wisata beserta ID-nya.  
- `df_user` memuat data informasi pengguna yang memberikan rating.  
"""

# Memuat data dari file CSV yang tersimpan di Google Drive ke dalam DataFrame pandas, sehingga data dapat diolah lebih lanjut dalam proyek sistem rekomendasi
df_rating = pd.read_csv('/content/drive/MyDrive/Sistem_Rekomendasi_CodingCamp/dataset/tourism_rating.csv')
df_place = pd.read_csv('/content/drive/MyDrive/Sistem_Rekomendasi_CodingCamp/dataset/tourism_with_id.csv')
df_user = pd.read_csv('/content/drive/MyDrive/Sistem_Rekomendasi_CodingCamp/dataset/user.csv')

"""## **Eksplorasi Awal Dataset**

Menampilkan ringkasan struktur, jumlah entri, dan tipe data dari dataset `df_rating`.
"""

# Menampilkan informasi data rating
df_rating.info()

"""Menampilkan detail struktur, jumlah baris, dan tipe kolom pada dataset `df_place`."""

# Menampilkan informasi data tempat wisata
df_place.info()

"""Menampilkan struktur, jumlah entri, dan tipe data pada dataset `df_user`."""

# Menampilkan informasi data user
df_user.info()

"""Menampilkan preview awal (5 baris teratas) dari dataset `df_place`."""

# Menampilkan 5 baris pertama data tempat wisata
df_place.head()

"""Menampilkan 5 baris awal dari dataset `df_user` untuk melihat struktur dan isinya."""

# Menampilkan 5 baris pertama data user
df_user.head()

"""Menampilkan 5 baris awal dari dataset `df_rating` untuk melihat isi data rating dari user ke tempat wisata."""

# Menampilkan 5 baris pertama data rating
df_rating.head()

"""## **Pembersihan dan Filter Data**

Menghapus kolom-kolom yang tidak relevan (`Time_Minutes`, `Unnamed: 11`, `Unnamed: 12`) dari dataset `df_place`.
"""

# Menghapus kolom yang tidak diperlukan pada dataset `df_place`
df_place = df_place.drop(['Time_Minutes','Unnamed: 11','Unnamed: 12'], axis=1)

"""Memilih hanya data tempat wisata yang berlokasi di Bandung dari dataset `df_place`."""

# Memilih data tempat wisata khusus di Bandung dari dataset `df_place`
df_place = df_place[df_place['City'] == 'Bandung']

"""Menampilkan 1 baris pertama dari dataset `df_place` untuk memastikan hasil filter dan pembersihan sudah sesuai."""

# Menampilkan 1 baris pertama dari dataset `df_place`
df_place.head(1)

"""Menggabungkan `df_rating` dengan `df_place` agar hanya menyisakan rating untuk tempat wisata di Bandung berdasarkan `Place_Id`."""

# Memilih data rating khusus untuk tempat wisata di Bandung berdasarkan `Place_Id`
df_rating = pd.merge(df_rating, df_place[['Place_Id']], how='right', on='Place_Id')

"""Menampilkan satu baris pertama dari `df_rating` untuk memastikan data rating hanya untuk tempat wisata di Bandung."""

# Menampilkan 1 baris pertama dari dataset `df_rating`
df_rating.head(1)

"""Memilih user yang memberi rating di Bandung, menghapus duplikat, lalu mengurutkan berdasarkan `User_Id`."""

# Memilih pengguna yang memberikan rating di Bandung berdasarkan `User_Id`, serta membersihkan dan mengurutkan data
df_user = pd.merge(df_user, df_rating[['User_Id']], how='right', on='User_Id').drop_duplicates().sort_values('User_Id')

"""Menampilkan 1 baris pertama dari `df_user` setelah difilter untuk pengguna yang memberikan rating di Bandung."""

# Menampilkan 1 baris pertama dari dataset `df_user`
df_user.head(1)

"""## **Visualisasi Data**

### **Tempat Wisata dengan Rating Terbanyak**

Menampilkan 10 tempat wisata terpopuler berdasarkan jumlah rating yang diberikan oleh pengguna.
"""

# Membuat DataFrame `top_10` yang berisi 10 tempat wisata di Bandung dengan jumlah rating terbanyak
top_10 = df_rating['Place_Id'].value_counts().reset_index(name='rating_count').rename(columns={'index': 'Place_Id'})[0:10]

# Menggabungkan data tersebut dengan nama tempat wisata
top_10 = pd.merge(top_10, df_place[['Place_Id','Place_Name']], how='left', on='Place_Id')

# Membuat visualisasi menggunakan bar plot untuk menampilkan 10 tempat wisata dengan rating terbanyak
plt.figure(figsize=(10,6))
sns.barplot(x='rating_count', y='Place_Name', data=top_10)
plt.title('10 Tempat Wisata dengan Rating Terbanyak di Bandung', pad=20)
plt.xlabel('Jumlah Rating')
plt.ylabel('Nama Tempat Wisata')
plt.tight_layout()
plt.show()

"""### **Perbandingan Kategori Tempat Wisata**

Menampilkan distribusi kategori tempat wisata, seperti kuliner, alam, hiburan, dan lainnya.
"""

# Memvisualisasikan distribusi jumlah tempat wisata berdasarkan kategori di Bandung
sns.countplot(y='Category', data=df_place)
plt.title('Perbandingan Jumlah Kategori Wisata di Bandung', pad=20)
plt.show()

"""### **Distribusi Usia Pengguna**

Menganalisis data demografi pengguna, mencakup distribusi usia dan kota asal.
"""

# Memvisualisasikan distribusi usia pengguna menggunakan boxplot
plt.figure(figsize=(5,3))
sns.boxplot(df_user['Age'])
plt.title('Distribusi Usia User', pad=20)
plt.show()

"""### **Asal Kota User**

Informasi ini dapat dimanfaatkan untuk mempersonalisasi rekomendasi sesuai asal kota maupun rentang usia pengguna.
"""

# Memvisualisasikan jumlah pengguna berdasarkan kota asal mereka
asal_kota = df_user['Location'].apply(lambda x: x.split(',')[0])

plt.figure(figsize=(8,6))
sns.countplot(y=asal_kota)
plt.title('Jumlah Asal Kota dari User')
plt.show()

"""### **Informasi Umum Tempat Wisata**

Menampilkan jumlah tempat wisata unik dan kategori wisata yang tersedia di dataset `df_place`.
"""

# Menampilkan informasi ringkasan tentang tempat wisata di Bandung
print(f"Terdapat {df_place['Place_Name'].nunique()} Tempat Wisata di Bandung")
print(f"Terdiri dari {df_place['Category'].nunique()} Kategori Wisata yaitu")
print('Kategori Wisata  :', df_place['Category'].unique())

"""### **Pie Chart Kategori Tempat Wisata**

Memvisualisasikan proporsi kategori tempat wisata menggunakan pie chart dan menampilkan jumlah tempat wisata untuk setiap kategori secara rinci.
"""

# Memvisualisasikan dan menampilkan jumlah tempat wisata berdasarkan kategori di Bandung
columns_category_type = df_place['Category'].unique().tolist()
plt.rcParams["figure.figsize"] = (15,8)
plt.pie(df_place['Category'].value_counts(), autopct='%1.1f%%',
        wedgeprops={'edgecolor': 'black'}, counterclock=False, shadow=True, startangle=25,
        radius=1.3, labels=columns_category_type, textprops={'fontsize': 15, 'weight': 'bold'})
plt.tight_layout()
plt.show()

for label, count in df_place['Category'].value_counts().items():
    print("Jumlah Tempat Wisata dengan Kategori", label, ":", count)

"""### **Jumlah User Berdasarkan Kota**

Menampilkan jumlah pengguna yang berasal dari masing-masing kota dengan mencetak nama kota dan total penggunanya.
"""

# Menampilkan jumlah pengguna berdasarkan kota asal mereka
for label, count in df_user['Location'].value_counts().items():
    print("Jumlah User dari Kota", label, ":", count)

"""## **Model Content Based Filtering**

Membuat representasi fitur kategori tempat wisata menggunakan TF-IDF (Term Frequency-Inverse Document Frequency), yang mengubah kategori menjadi vektor angka untuk analisis kemiripan.
"""

# Membuat model Content-Based Filtering berbasis kategori tempat wisata dengan menggunakan TF-IDF
tfidf_vectorizer_for_category = TfidfVectorizer()
tfidf_vectorizer_for_category.fit(df_place['Category'])
tfidf_vectorizer_for_category.get_feature_names_out()

"""Mengubah data kategori tempat wisata menjadi matriks numerik menggunakan TF-IDF, lalu menampilkan dimensi matriks (jumlah tempat wisata Ã— jumlah fitur kategori)."""

# Mengubah data kategori tempat wisata menjadi representasi numerik menggunakan TF-IDF dan mengecek dimensinya
tfidf_matrix = tfidf_vectorizer_for_category.fit_transform(df_place['Category'])
tfidf_matrix.shape

"""Mengubah matriks TF-IDF yang berupa format sparse menjadi matriks penuh (dense matrix) agar nilai-nilai TF-IDF dapat dilihat secara lengkap dan eksplisit."""

# Mengonversi matriks TF-IDF menjadi matriks penuh untuk melihat semua nilainya secara eksplisit
tfidf_matrix.todense()

"""Membuat DataFrame dari matriks TF-IDF kategori dengan nama tempat sebagai indeks dan kata-kata kategori sebagai kolom, lalu menampilkan 10 baris acak untuk melihat contoh representasi fitur tiap tempat wisata."""

# Menampilkan 10 baris acak dari DataFrame yang berisi nilai TF-IDF kategori untuk setiap tempat wisata
pd.DataFrame(
    tfidf_matrix.todense(),
    columns=tfidf_vectorizer_for_category.get_feature_names_out(),
    index=df_place.Place_Name
).sample(10, axis=0)

"""Menghitung matriks kemiripan cosine antar tempat wisata berdasarkan representasi TF-IDF kategori, untuk mengukur seberapa mirip kategori antar tempat wisata satu dengan lainnya.

"""

# Menghitung matriks kemiripan cosine antar tempat wisata berdasarkan representasi TF-IDF kategori mereka
cosine_sim = cosine_similarity(tfidf_matrix)
cosine_sim

"""Mengubah matriks kemiripan cosine menjadi DataFrame dengan indeks dan kolom berupa nama tempat wisata, memudahkan analisis dan visualisasi kemiripan antar tempat wisata, serta menampilkan ukuran matriks dan 10 baris contoh secara acak.

"""

# Membuat DataFrame dari matriks kemiripan cosine dengan nama tempat wisata sebagai indeks dan kolom, menampilkan ukuran matriks, serta menampilkan 10 baris data secara acak
cosine_sim_df = pd.DataFrame(
    cosine_sim, index=df_place.Place_Name, columns=df_place.Place_Name)
print('Shape:', cosine_sim_df.shape)

cosine_sim_df.sample(10, axis=0)

"""Memberikan rekomendasi tempat wisata yang serupa berdasarkan kategori."""

# Fungsi ini memberikan rekomendasi tempat wisata mirip berdasarkan kemiripan cosine kategori, dengan menerima nama tempat sebagai input dan mengembalikan daftar k tempat wisata terdekat
def destination_recommendations(place_name, similarity_data=cosine_sim_df, items=df_place[['Place_Name', 'Category']], k=10):
    index = similarity_data.loc[:,place_name].to_numpy().argpartition(range(-1, -k, -1))
    closest = similarity_data.columns[index[-1:-(k+2):-1]]
    closest = closest.drop(place_name, errors='ignore')
    return pd.DataFrame(closest).merge(items).head(k)

"""Menampilkan seluruh informasi tempat wisata yang bernama "Museum Gedung Sate" dari dataset `df_place`.

"""

# Menampilkan data lengkap tempat wisata dengan nama "Museum Gedung Sate" dari dataset `df_place`
place_name = 'Museum Gedung Sate'
df_place[df_place.Place_Name.eq(place_name)]

"""Memanggil fungsi `destination_recommendations` untuk memberikan daftar tempat wisata yang memiliki kategori serupa dengan "Museum Gedung Sate" berdasarkan sistem rekomendasi berbasis konten.

"""

# Memanggil fungsi rekomendasi untuk mendapatkan daftar tempat wisata serupa berdasarkan kategori dari "Museum Gedung Sate"
destination_recommendations(place_name=place_name)

"""Menghitung nilai *precision* pada *top-k* rekomendasi berdasarkan kesamaan kategori tempat wisata dengan item input, untuk mengukur akurasi model rekomendasi.

"""

# Fungsi untuk mengevaluasi akurasi model rekomendasi berbasis konten dengan menghitung precision@k berdasarkan kesamaan kategori tempat wisata
def evaluate_cbf_precision_at_k(place_name, k=10):
    # Mendapatkan kategori tempat input
    input_category = df_place[df_place['Place_Name'] == place_name]['Category'].iloc[0]

    # Mendapatkan rekomendasi
    recommendations = destination_recommendations(place_name, k=k)

    # Menghitung item yang relevan (kategori sama)
    relevant_count = sum(1 for cat in recommendations['Category'] if cat == input_category)

    precision = relevant_count / k
    return precision, relevant_count

"""Mengukur akurasi rekomendasi dengan menghitung proporsi tempat wisata yang termasuk kategori sama di antara 5 rekomendasi teratas untuk tempat tersebut.

"""

# Menghitung nilai precision@5 dari rekomendasi berbasis kategori untuk tempat wisata "Museum Gedung Sate"
evaluate_cbf_precision_at_k("Museum Gedung Sate", k=5)

"""Menghitung proporsi tempat wisata yang relevan (berkategori sama) dari 10 rekomendasi teratas untuk meningkatkan evaluasi akurasi sistem rekomendasi.

"""

# Menghitung nilai precision@10 dari rekomendasi berbasis kategori untuk tempat wisata "Museum Gedung Sate"
evaluate_cbf_precision_at_k("Museum Gedung Sate", k=10)

"""## **Model Collaborative**

**1. Membuat Salinan Data rating**

Membuat salinan dataset rating dan menampilkan beberapa baris pertama untuk pemeriksaan awal.
"""

# Membaca dataset untuk dilakukan encoding
df = df_rating.copy()
df.head()

"""**2. Melakukan Encoding**

Fungsi untuk membuat dictionary encoding dan decoding nilai unik dari suatu kolom dalam dataframe.
"""

def dict_encoder(col, data=df):

  # Mengubah kolom suatu dataframe menjadi list tanpa nilai yang sama
  unique_val = data[col].unique().tolist()

  # Melakukan encoding value kolom suatu dataframe ke angka
  val_to_val_encoded = {x: i for i, x in enumerate(unique_val)}

  # Melakukan proses encoding angka ke value dari kolom suatu dataframe
  val_encoded_to_val = {i: x for i, x in enumerate(unique_val)}
  return val_to_val_encoded, val_encoded_to_val

"""Melakukan encoding pada kolom `User_Id` menjadi angka, kemudian menambahkan kolom baru `user` berisi hasil encoding tersebut ke dataframe."""

# Encoding User_Id
user_to_user_encoded, user_encoded_to_user = dict_encoder('User_Id')

# Mapping User_Id ke dataframe
df['user'] = df['User_Id'].map(user_to_user_encoded)

"""Melakukan encoding pada kolom `Place_Id` menjadi angka, kemudian menambahkan kolom baru `place` berisi hasil encoding tersebut ke dataframe."""

# Encoding Place_Id
place_to_place_encoded, place_encoded_to_place = dict_encoder('Place_Id')

# Mapping Place_Id ke dataframe place
df['place'] = df['Place_Id'].map(place_to_place_encoded)

"""Menghitung jumlah user dan tempat unik, mengonversi rating ke tipe float, serta menampilkan nilai rating minimum dan maksimum."""

# Mendapatkan jumlah user dan place
num_users, num_place = len(user_to_user_encoded), len(place_to_place_encoded)

# Mengubah rating menjadi nilai float
df['Place_Ratings'] = df['Place_Ratings'].values.astype(np.float32)

# Mendapatkan nilai minimum dan maksimum rating
min_rating, max_rating = min(df['Place_Ratings']), max(df['Place_Ratings'])

print(f'Number of User: {num_users}, Number of Place: {num_place}, Min Rating: {min_rating}, Max Rating: {max_rating}')

"""Mengacak urutan data dalam dataset untuk menghindari bias urutan, lalu menampilkan dua baris pertama."""

# Mengacak dataset
df = df.sample(frac=1, random_state=42)
df.head(2)

"""## **Pemodelan Machine Learning dengan RecommenderNet**

Mempersiapkan data fitur (user dan tempat) dan target (rating ternormalisasi), lalu membagi dataset menjadi 80% data pelatihan dan 20% data validasi.
"""

# Membuat variabel x untuk mencocokkan data user dan place menjadi satu value
x = df[['user', 'place']].values

# Membuat variabel y untuk membuat rating dari hasil
y = df['Place_Ratings'].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values

# Membagi menjadi 80% data train dan 20% data validasi
train_indices = int(0.8 * df.shape[0])
x_train, x_val, y_train, y_val = (
    x[:train_indices],
    x[train_indices:],
    y[:train_indices],
    y[train_indices:]
)

"""Model ini menggunakan embedding untuk merepresentasikan user dan tempat wisata, lalu memprediksi rating dengan menghitung dot product dan menambahkan bias, hasil akhirnya diaktivasi dengan fungsi sigmoid."""

class RecommenderNet(tf.keras.Model):

  def __init__(self, num_users, num_places, embedding_size, **kwargs):
    super(RecommenderNet, self).__init__(**kwargs)
    self.num_users = num_users
    self.num_places = num_places
    self.embedding_size = embedding_size

    # Membuat layer embedding untuk user dengan regularisasi L2 dan inisialisasi He normal
    self.user_embedding = layers.Embedding(
        num_users,
        embedding_size,
        embeddings_initializer='he_normal',
        embeddings_regularizer=keras.regularizers.l2(1e-6)
    )
    # Bias untuk setiap user
    self.user_bias = layers.Embedding(num_users, 1)

    # Membuat layer embedding untuk tempat wisata dengan regularisasi dan inisialisasi sama
    self.places_embedding = layers.Embedding(
        num_places,
        embedding_size,
        embeddings_initializer='he_normal',
        embeddings_regularizer=keras.regularizers.l2(1e-6)
    )
    # Bias untuk setiap tempat wisata
    self.places_bias = layers.Embedding(num_places, 1)

  def call(self, inputs):
    # Mendapatkan embedding user dan biasnya dari input
    user_vector = self.user_embedding(inputs[:, 0])
    user_bias = self.user_bias(inputs[:, 0])
    # Mendapatkan embedding tempat wisata dan biasnya dari input
    places_vector = self.places_embedding(inputs[:, 1])
    places_bias = self.places_bias(inputs[:, 1])

    # Menghitung dot product antara user dan tempat wisata
    dot_user_places = tf.tensordot(user_vector, places_vector, 2)
    # Menambahkan bias user dan tempat wisata ke hasil dot product
    x = dot_user_places + user_bias + places_bias

    # Menggunakan sigmoid untuk output prediksi rating antara 0 dan 1
    return tf.nn.sigmoid(x)

"""Membuat instance model `RecommenderNet` dengan ukuran embedding 50, kemudian mengompilasi model dengan loss function Binary Crossentropy, optimizer Adam dengan learning rate 0.0004, dan metrik evaluasi Root Mean Squared Error (RMSE)."""

model = RecommenderNet(num_users, num_place, 50)  # Inisialisasi model dengan embedding size 50

# Kompilasi model dengan loss binary crossentropy dan optimizer Adam
model.compile(
    loss=tf.keras.losses.BinaryCrossentropy(),
    optimizer=keras.optimizers.Adam(learning_rate=0.0004),
    metrics=[tf.keras.metrics.RootMeanSquaredError()]
)

"""Menghentikan pelatihan jika RMSE validasi kurang dari 0.35."""

class myCallback(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs={}):
        # Cek nilai RMSE validasi setelah tiap epoch
        if logs.get('val_root_mean_squared_error') < 0.35:
            print('Lapor! Metriks validasi sudah sesuai harapan')
            self.model.stop_training = True  # Hentikan pelatihan jika kondisi terpenuhi

"""Melakukan training model menggunakan data latih dan validasi, dengan callback untuk menghentikan proses jika kriteria terpenuhi."""

# Memulai training
history = model.fit(
    x=x_train,
    y=y_train,
    epochs=100,
    validation_data=(x_val, y_val),
    callbacks=[myCallback()]
)

"""Menampilkan grafik Root Mean Squared Error (RMSE) pada data training dan validasi selama proses pelatihan."""

# Menampilkan plot loss dan validation
plt.plot(history.history['root_mean_squared_error'])
plt.plot(history.history['val_root_mean_squared_error'])
plt.title('Model Metrics')
plt.ylabel('Root Mean Squared Error')
plt.xlabel('Epoch')
plt.ylim(ymin=0, ymax=0.4)
plt.legend(['Train', 'Validation'], loc='center left')
plt.show()

"""## **Prediksi Top 10 Rekomendasi Pariwisata di Bandung**

Membuat dataframe baru `place_df` dengan kolom penting dari `df_place` dan mengganti nama kolom agar lebih singkat dan konsisten, serta menyalin data rating ke dataframe `df`.
"""

# Menyiapkan dataframe
place_df = df_place[['Place_Id','Place_Name','Category','Rating','Price']]
place_df.columns = ['id','place_name','category','rating','price']
df = df_rating.copy()

"""Memilih satu `user_id` secara acak dari data rating, lalu mengambil semua tempat wisata yang pernah dikunjungi oleh user tersebut."""

# Mengambil sample user
user_id = df.User_Id.sample(1).iloc[0]
place_visited_by_user = df[df.User_Id == user_id]

"""Membuat daftar ID tempat wisata yang belum dikunjungi oleh user terpilih, mengubahnya ke dalam format encoded, dan menggabungkan dengan ID user untuk digunakan sebagai input pada model rekomendasi."""

# Membuat data lokasi yang belum dikunjungi user
place_not_visited = place_df[~place_df['id'].isin(place_visited_by_user.Place_Id.values)]['id']
place_not_visited = list(
    set(place_not_visited)
    .intersection(set(place_to_place_encoded.keys()))
)

place_not_visited = [[place_to_place_encoded.get(x)] for x in place_not_visited]
user_encoder = user_to_user_encoded.get(user_id)
user_place_array = np.hstack(
    ([[user_encoder]] * len(place_not_visited), place_not_visited)
)

"""Melakukan prediksi rating untuk tempat-tempat yang belum dikunjungi user, memilih 10 dengan rating tertinggi, lalu menampilkan rekomendasi tersebut bersama 5 tempat favorit user."""

# Prediksi rating untuk semua tempat yang belum dikunjungi user
ratings = model.predict(user_place_array).flatten()

# Ambil indeks 10 tempat dengan rating prediksi tertinggi
top_ratings_indices = ratings.argsort()[-10:][::-1]

# Ambil ID tempat dari hasil prediksi terbaik
recommended_place_ids = [
    place_encoded_to_place.get(place_not_visited[idx][0])
    for idx in top_ratings_indices
]

# Header rekomendasi
print(f"Daftar rekomendasi untuk: User {user_id}")
print("=" * 45, '\n')

# Menampilkan 5 tempat dengan rating tertinggi yang pernah dikunjungi user
print("Tempat dengan rating wisata paling tinggi dari user")
print("-" * 60)

top_place_user_ids = (
    place_visited_by_user
    .sort_values(by='Place_Ratings', ascending=False)
    .head(5)
    .Place_Id
    .values
)

top_place_user_df = place_df[place_df['id'].isin(top_place_user_ids)]

for row in top_place_user_df.itertuples():
    print(f"{row.place_name} : {row.category}")

print("\n" + "-" * 60)
print("Top 10 Rekomendasi Tempat Wisata untuk Anda")
print("-" * 60)

# Menampilkan daftar 10 tempat rekomendasi
recommended_places_df = place_df[place_df['id'].isin(recommended_place_ids)]

for i, row in enumerate(recommended_places_df.itertuples(), start=1):
    print(f"{i}. {row.place_name}")
    print(f"    Kategori       : {row.category}")
    print(f"    Harga Tiket    : {row.price}")
    print(f"    Rating Wisata  : {row.rating}\n")

print("=" * 45)

"""**Insight Akhir:**

* Jumlah tempat wisata di Bandung sangat beragam, sehingga rekomendasi bisa dibuat baik menggunakan pendekatan *content-based* (berdasarkan kategori/tempat mirip) maupun *collaborative filtering* (berdasarkan rating user).

* Sistem rekomendasi ini memiliki potensi besar untuk dikembangkan menjadi aplikasi mobile/web,
  di mana rekomendasi bisa dipersonalisasi lebih dalam dengan memasukkan data seperti lokasi real-time, preferensi, dan aktivitas pengguna.
"""